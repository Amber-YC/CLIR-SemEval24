{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deca9254-c41a-4e83-b97d-d3ba7db7135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from preprocessing import load_train_data, load_eval_data\n",
    "import sklearn\n",
    "\n",
    "# inputs = tokenizer(\"Hello world!\", return_tensors=\"pt\")\n",
    "# outputs = model(**inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0153510-db27-44e5-b3bc-92568b018c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Multilingual-MiniLM-L12-H384\")\n",
    "model = AutoModel.from_pretrained(\"microsoft/Multilingual-MiniLM-L12-H384\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3102f48f-bd24-49bd-8c24-bd589b29a1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(batch_size, text_pairs, labels=None, shuffle=True):\n",
    "    total_data_size = len(text_pairs)\n",
    "    index_ls = [i for i in range(total_data_size)]\n",
    "    \n",
    "    if shuffle:\n",
    "        dataset = sklearn.utils.shuffle(index_ls)\n",
    "        \n",
    "    if labels: \n",
    "        for start_i in range(0, total_data_size, batch_size):\n",
    "            # get batch_texts, batch_labels\n",
    "            end_i = min(total_data_size, start_i + batch_size)\n",
    "            batch_text_pairs = text_pairs[start_i:end_i]\n",
    "            batch_labels = labels[start_i:end_i]\n",
    "            yield batch_text_pairs, batch_labels\n",
    "        \n",
    "    else:\n",
    "        for start_i in range(0, total_data_size, batch_size):\n",
    "            # get batch_texts\n",
    "            end_i = min(total_data_size, start_i + batch_size)\n",
    "            batch_text_pairs = text_pairs[start_i:end_i]\n",
    "            yield batch_text_pairs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb22af21-ce2a-4525-b507-bf4e0d58b2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[     0,   1650,    450,  96276,      4,   1660,  50065,     70,  76329,\n",
      "              5,      2,      2,   2174,    450,  17669,  96276,      4,   1660,\n",
      "          50065,     70,  76329,      5,      2,      1,      1,      1,      1,\n",
      "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "              1,      1,      1,      1,      1,      1,      1],\n",
      "        [     0,     62,  22556,  10269,  51042,   8305,   7401,      5,      2,\n",
      "              2,     62,  22556,  10269,     83,  51042,   8305,   3060,   7401,\n",
      "              5,      2,      1,      1,      1,      1,      1,      1,      1,\n",
      "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "              1,      1,      1,      1,      1,      1,      1],\n",
      "        [     0,     87,     25,    272,   2809, 157318,   2347,  64194,   1563,\n",
      "          31804,    100,    398,      5,      2,      2,     87,     25,     39,\n",
      "          16487,    100,    398,    756,    645,     70,   1563,  31804,      5,\n",
      "              2,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "              1,      1,      1,      1,      1,      1,      1],\n",
      "        [     0,   4263,    764,     83,   4127,  16487,    136,   1556,     10,\n",
      "           4127,   3357,   2481,      4,    764,  13648,    186,  80560,     20,\n",
      "           1284,     83,   1286,  47041,    333,  91153,      5,      2,      2,\n",
      "           4263,    764,     25,      7,   4127,  16487,      4,    136,     10,\n",
      "           4127,   3357,   2481,      4,    764, 177641,  18544,    186,  80560,\n",
      "              4,   1284,   1286,  47041,    333,      5,      2],\n",
      "        [     0,   4687,  14602,    959,  35463,    398,      4,   2412,     83,\n",
      "           1660,   8668,     53,    297,    678,    398,      5,      2,      2,\n",
      "           4687,  22027,     25,     18,  35463,    398,      4,   2412,     83,\n",
      "           1660,   8668,     53,    297,      5,      2,      1,      1,      1,\n",
      "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "              1,      1,      1,      1,      1,      1,      1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "# test by loading the data:\n",
    "train_file_eng = '../data/TrackA_data/eng/eng_train.csv'\n",
    "eval_file_afr = '../data/TrackC_data/afr/afr_pilot.csv'\n",
    "train_pairs_eng, train_scores_eng = load_train_data(train_file_eng)\n",
    "eval_pairs_afr = load_eval_data(eval_file_afr)\n",
    "# print(train[0][:5])\n",
    "# print(train[1][:5])\n",
    "# print(test[:5])\n",
    "\n",
    "train_batches_eng = list(get_batches(5, train_pairs_eng, shuffle=True))\n",
    "\n",
    "# for batch in train_batches_eng:\n",
    "#     encoded_input = tokenizer(batch, padding=True, return_tensors=\"pt\")\n",
    "#     output = miniLM_model(**encoded_input)\n",
    "\n",
    "'''usage of Transformer'''\n",
    "encoded_input = miniLM_tokenizer(train_batches_eng[0], padding=True, return_tensors=\"pt\")\n",
    "output = miniLM_model(**encoded_input)\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9e133d-87c7-4f45-83b5-814428b760c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
