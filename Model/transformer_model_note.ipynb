{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deca9254-c41a-4e83-b97d-d3ba7db7135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from preprocessing import load_train_data, load_eval_data\n",
    "import sklearn\n",
    "\n",
    "# inputs = tokenizer(\"Hello world!\", return_tensors=\"pt\")\n",
    "# outputs = model(**inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0153510-db27-44e5-b3bc-92568b018c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Multilingual-MiniLM-L12-H384\")\n",
    "model = AutoModel.from_pretrained(\"microsoft/Multilingual-MiniLM-L12-H384\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3102f48f-bd24-49bd-8c24-bd589b29a1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(batch_size, text_pairs, labels=None, shuffle=True):\n",
    "    total_data_size = len(text_pairs)\n",
    "    index_ls = [i for i in range(total_data_size)]\n",
    "    \n",
    "    if shuffle:\n",
    "        dataset = sklearn.utils.shuffle(index_ls)\n",
    "        \n",
    "    if labels: \n",
    "        for start_i in range(0, total_data_size, batch_size):\n",
    "            # get batch_texts, batch_labels\n",
    "            end_i = min(total_data_size, start_i + batch_size)\n",
    "            batch_text_pairs = text_pairs[start_i:end_i]\n",
    "            batch_labels = labels[start_i:end_i]\n",
    "            yield batch_text_pairs, batch_labels\n",
    "        \n",
    "    else:\n",
    "        for start_i in range(0, total_data_size, batch_size):\n",
    "            # get batch_texts\n",
    "            end_i = min(total_data_size, start_i + batch_size)\n",
    "            batch_text_pairs = text_pairs[start_i:end_i]\n",
    "            yield batch_text_pairs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb22af21-ce2a-4525-b507-bf4e0d58b2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test by loading the data:\n",
    "train_file_eng = '../data/TrackA_data/eng/eng_train.csv'\n",
    "eval_file_afr = '../data/TrackC_data/afr/afr_pilot.csv'\n",
    "train_pairs_eng, train_scores_eng = load_train_data(train_file_eng)\n",
    "eval_pairs_afr = load_eval_data(eval_file_afr)\n",
    "# print(train[0][:5])\n",
    "# print(train[1][:5])\n",
    "# print(test[:5])\n",
    "\n",
    "train_batches_eng = list(get_batches(5, train_pairs_eng, shuffle=True))\n",
    "\n",
    "# for batch in train_batches_eng:\n",
    "#     encoded_input = tokenizer(batch, padding=True, return_tensors=\"pt\")\n",
    "#     output = miniLM_model(**encoded_input)\n",
    "\n",
    "'''usage of Transformer'''\n",
    "encoded_input = miniLM_tokenizer(train_batches_eng[0], padding=True, return_tensors=\"pt\")\n",
    "output = miniLM_model(**encoded_input)\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9e133d-87c7-4f45-83b5-814428b760c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "torch-gpuprivate",
   "language": "python",
   "display_name": "torch-gpuprivate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
